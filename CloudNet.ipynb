{"cells":[{"cell_type":"markdown","metadata":{"id":"63xqAEcbQOJE"},"source":["# Import packages"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"WtJ563lzylfQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-WICsmXQOg9"},"outputs":[],"source":["# Import necessary packages.\n","import numpy as np\n","import pandas as pd\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from PIL import Image\n","\n","# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n","from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n","from torchvision.datasets import DatasetFolder, VisionDataset\n","\n","# This is for the progress bar.\n","from tqdm.auto import tqdm\n","import random\n","\n","# This if for organize files\n","import shutil\n","\n","# For plotting learning curve\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eyc638hzQmZq"},"outputs":[],"source":["myseed = 6666  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)"]},{"cell_type":"markdown","metadata":{"id":"kZK_4jyClVo1"},"source":["# Organize files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3Q8PFVujGhC"},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/Data/SWIMCAT')\n","path = os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ss6PqHd8nkog"},"outputs":[],"source":["def mkfile(file):\n","    if not os.path.exists(file):\n","        os.makedirs(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NB1QVvGmIAy"},"outputs":[],"source":["# Create training and validation set\n","mkfile('/content/drive/MyDrive/CloudNet/SWIMCAT/train')\n","mkfile('/content/drive/MyDrive/CloudNet/SWIMCAT/val')\n","# mkfile('/content/drive/MyDrive/CloudNet/SWIMCAT/test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHNSBjcpqDOA"},"outputs":[],"source":["# training : validation = 7 : 3\n","split_rate = 0.3\n","cloud_class = [cla for cla in os.listdir(path)]\n","cloud_class\n","\n","for cla in cloud_class:\n","    cla_path = path + '/' + cla + '/'\n","    images = os.listdir(cla_path) # images列表存储了该目录下所有图像的名称\n","    num = len(images)\n","    eval_index = random.sample(images, k=int(num * split_rate)) # 对数据进行划分\n","    train_index = int(0)\n","    val_index = int(0)\n","    for index, image in enumerate(images):\n","        # eval_index 中保存验证集val的图像名称\n","        if image in eval_index:\n","            image_path = cla_path + image\n","            new_path = '/content/drive/MyDrive/CloudNet/SWIMCAT/val'\n","            shutil.copy(image_path, new_path + '/' + cla[0] + '_' + str(val_index))  # 选中的图像进行复制\n","            val_index = val_index + 1\n","        else:\n","            image_path = cla_path + image\n","            new_path = '/content/drive/MyDrive/CloudNet/SWIMCAT/train'\n","            shutil.copy(image_path, new_path + '/' + cla[0] + '_' + str(train_index))  # 选中的图像进行复制\n","            train_index = train_index + 1\n","        print(\"\\r[{}] processing [{}/{}]\".format(cla, index + 1, num), end=\"\")\n","    print()\n","\n","print(\"processing done!\")"]},{"cell_type":"markdown","metadata":{"id":"Vn5iB6H_USd0"},"source":["# Transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8zNwn1QUURs"},"outputs":[],"source":["# Normally, We don't need augmentations in testing and validation.\n","# All we need here is to resize the PIL image and transform it into Tensor.\n","test_tfm = transforms.Compose([\n","    # use for dataset SWIMCAT\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor()\n","])\n","\n","# However, it is also possible to use augmentation in the testing phase.\n","# You may use train_tfm to produce a variety of images and then test using ensemble methods\n","train_tfm = transforms.Compose([\n","    # Resize the image into a fixed shape (height = width = 128)\n","    # use for dataset SWIMCAT\n","    transforms.Resize((128, 128)),\n","    # You may add some transforms here.\n","    transforms.RandomHorizontalFlip(p = 0.5),\n","    transforms.RandomVerticalFlip(p = 0.5),\n","    transforms.RandomCrop(size = (128, 128)),\n","    transforms.ColorJitter(brightness = 0.5, contrast = 0.5, saturation = 0.5, hue = 0.1),\n","    # ToTensor() should be the last one of the transforms.\n","    transforms.ToTensor(),\n","    # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n","])\n"]},{"cell_type":"markdown","metadata":{"id":"SlXCJforQo_A"},"source":["# Datasets"]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive/CloudNet/SWIMCAT')\n","path = os.getcwd()"],"metadata":{"id":"Ac84rEJFMdKo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A6A3Pi8aQnP1"},"outputs":[],"source":["class SWIMCATDataset(Dataset):\n","\n","    def __init__(self,path,tfm=test_tfm,files = None):\n","        super(SWIMCATDataset).__init__()\n","        self.path = path\n","        # print(os.listdir(path))\n","        self.files = sorted([os.path.join(path,x) for x in os.listdir(path)])\n","        # print(len(self.files))\n","        if files != None:\n","            self.files = files\n","        print(f\"One {path} sample\",self.files[0])\n","        self.transform = tfm\n","  \n","    def __len__(self):\n","        return len(self.files)\n","  \n","    def __getitem__(self,idx):\n","        fname = self.files[idx]\n","        # print(fname.split(\"/\")[-1])\n","        im = Image.open(fname)\n","        im = self.transform(im)\n","        #im = self.data[idx]\n","        # label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n","        try:\n","            # use for dataset SWIMCAT\n","            label = int(ord(fname.split(\"/\")[-1].split(\"_\")[0])-ord('A'))\n","        except:\n","            label = -1 # test has no label\n","        return im,label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dIROqNOK72CE"},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n","        # input 維度 [3, 128, 128]\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n","\n","            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n","\n","            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n","\n","            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n","            \n","            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(512*4*4, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 5)\n","        )\n","\n","    def forward(self, x):\n","      out = self.cnn(x)\n","      out = out.view(out.size()[0], -1)\n","      return self.fc(out)\n","\n","        \n","if __name__ == '__main__':\n","    x = torch.rand([1, 3, 128, 128])\n","    model = Classifier()\n","    y = model(x)\n","    print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"roZye4XO-Mph"},"outputs":[],"source":["batch_size = 32\n","_dataset_dir = '/content/drive/MyDrive/CloudNet/SWIMCAT'\n","# print(os.path.join(_dataset_dir,\"train\"))\n","# Construct datasets.\n","# The argument \"loader\" tells how torchvision reads the data.\n","train_set = SWIMCATDataset(os.path.join(_dataset_dir,\"train\"), tfm=train_tfm)\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","valid_set = SWIMCATDataset(os.path.join(_dataset_dir,\"val\"), tfm=test_tfm)\n","valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O9Ly7i12HGXM"},"outputs":[],"source":["_exp_name = \"sample\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UFijMK1oCP0I"},"outputs":[],"source":["# \"cuda\" only when GPUs are available.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# The number of training epochs and patience.\n","n_epochs = 300\n","patience = 50 # If no improvement in 'patience' epochs, early stop\n","\n","# Initialize a model, and put it on the device specified.\n","model = Classifier().to(device)\n","\n","# For the classification task, we use cross-entropy as the measurement of performance.\n","criterion = nn.CrossEntropyLoss()\n","\n","# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5) \n","\n","# Writer of tensorboard\n","writer = SummaryWriter()\n","\n","# Initialize trackers, these are not parameters and should not be changed\n","stale = 0\n","best_acc = 0\n","\n","for epoch in range(n_epochs):\n","\n","    # ---------- Training ----------\n","    # Make sure the model is in train mode before training.\n","    model.train()\n","\n","    # These are used to record information in training.\n","    train_loss = []\n","    train_accs = []\n","\n","    for batch in tqdm(train_loader):\n","\n","        # A batch consists of image data and corresponding labels.\n","        imgs, labels = batch\n","        # imgs = imgs.half()\n","        # print(imgs.shape,labels.shape)\n","\n","        # Forward the data. (Make sure data and model are on the same device.)\n","        logits = model(imgs.to(device))\n","\n","        # print(logits)\n","        # print(labels)\n","\n","        # Calculate the cross-entropy loss.\n","        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n","        loss = criterion(logits, labels.to(device))\n","\n","        # Gradients stored in the parameters in the previous step should be cleared out first.\n","        optimizer.zero_grad()\n","\n","        # Compute the gradients for parameters.\n","        loss.backward()\n","\n","        # Clip the gradient norms for stable training.\n","        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n","\n","        # Update the parameters with computed gradients.\n","        optimizer.step()\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        # Record the loss and accuracy.\n","        train_loss.append(loss.item())\n","        train_accs.append(acc)\n","        \n","    train_loss = sum(train_loss) / len(train_loss)\n","    train_acc = sum(train_accs) / len(train_accs)\n","    writer.add_scalar('Loss/Train', train_loss, epoch)\n","    writer.add_scalar('Acc/Train', train_acc, epoch)\n","\n","    # Print the information.\n","    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n","\n","    # ---------- Validation ----------\n","    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n","    model.eval()\n","\n","    # These are used to record information in validation.\n","    valid_loss = []\n","    valid_accs = []\n","\n","    # Iterate the validation set by batches.\n","    for batch in tqdm(valid_loader):\n","\n","        # A batch consists of image data and corresponding labels.\n","        imgs, labels = batch\n","        #imgs = imgs.half()\n","\n","        # We don't need gradient in validation.\n","        # Using torch.no_grad() accelerates the forward process.\n","        with torch.no_grad():\n","            logits = model(imgs.to(device))\n","\n","        # We can still compute the loss (but not the gradient).\n","        loss = criterion(logits, labels.to(device))\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        # Record the loss and accuracy.\n","        valid_loss.append(loss.item())\n","        valid_accs.append(acc)\n","        # break\n","\n","    # The average loss and accuracy for entire validation set is the average of the recorded values.\n","    valid_loss = sum(valid_loss) / len(valid_loss)\n","    valid_acc = sum(valid_accs) / len(valid_accs)\n","\n","    writer.add_scalar('Loss/Valid', valid_loss, epoch)\n","    writer.add_scalar('Acc/Valid', valid_acc, epoch)\n","\n","    # Print the information.\n","    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","\n","\n","    # update logs\n","    if valid_acc > best_acc:\n","        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n","            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n","    else:\n","        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n","            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","\n","\n","    # save models\n","    if valid_acc > best_acc:\n","        print(f\"Best model found at epoch {epoch}, saving model\")\n","        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n","        best_acc = valid_acc\n","        stale = 0\n","    else:\n","        stale += 1\n","        if stale > patience:\n","            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n","            break"]},{"cell_type":"markdown","source":["# Visualization"],"metadata":{"id":"ljM4vh81e7cH"}},{"cell_type":"markdown","source":[],"metadata":{"id":"oNuS101PcHyy"}},{"cell_type":"code","source":["%reload_ext tensorboard\n","%tensorboard --logdir=./runs/"],"metadata":{"id":"CmxE8HhMe08J"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}